{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vvQfycnZEiFk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential #type: ignore\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Attention #type: ignore\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau #type: ignore\n",
        "from tensorflow.keras.regularizers import l2 #type: ignore\n",
        "from scipy.stats import entropy\n",
        "import webbrowser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(r\"C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\INTEL CBE\\extended_keystroke_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (30000, 17)\n",
            "\n",
            "Feature summary:\n",
            "       avg_keystroke_time  std_keystroke_time  avg_pause_time  std_pause_time  \\\n",
            "count        30000.000000        30000.000000    30000.000000    30000.000000   \n",
            "mean             0.125015            0.029564        0.299886        0.123109   \n",
            "std              0.075180            0.020050        0.200939        0.075384   \n",
            "min              0.044156            0.005124        0.068358        0.023456   \n",
            "25%              0.050007            0.009859        0.100043        0.049234   \n",
            "50%              0.108581            0.020703        0.246610        0.091680   \n",
            "75%              0.199969            0.049281        0.499591        0.196799   \n",
            "max              0.232398            0.076009        0.651534        0.300335   \n",
            "\n",
            "       avg_key_hold_time  std_key_hold_time  typing_speed  rhythm_consistency  \\\n",
            "count       30000.000000       30000.000000  30000.000000        3.000000e+04   \n",
            "mean            0.074991           0.019689      6.026807                -inf   \n",
            "std             0.025189           0.010107      4.052663                 NaN   \n",
            "min             0.043486           0.004745      1.534840                -inf   \n",
            "25%             0.049980           0.009834      2.001639        3.643384e+00   \n",
            "50%             0.069363           0.015735      5.079883        4.053660e+00   \n",
            "75%             0.099983           0.029557      9.995747        4.350286e+00   \n",
            "max             0.121265           0.044156     14.628859        4.582427e+00   \n",
            "\n",
            "       avg_key_distance  std_key_distance    error_rate  correction_rate  \\\n",
            "count      30000.000000      30000.000000  30000.000000     30000.000000   \n",
            "mean           1.750018          0.739567      0.024990         0.366907   \n",
            "std            0.274730          0.259383      0.033314         0.438438   \n",
            "min            1.166370          0.265374      0.000000         0.000000   \n",
            "25%            1.499240          0.492378      0.000000         0.000000   \n",
            "50%            1.667571          0.662975      0.000000         0.000000   \n",
            "75%            2.001369          0.987240      0.046512         0.857143   \n",
            "max            2.668890          1.444184      0.250000         1.000000   \n",
            "\n",
            "       copy_paste_frequency   mouse_speed  mouse_acceleration    mouse_jerk  \n",
            "count          30000.000000  30000.000000        30000.000000  30000.000000  \n",
            "mean               0.059950    650.162273          150.013927     75.084940  \n",
            "std                0.052213    169.297791           62.663220     33.523465  \n",
            "min                0.000000    -22.066002          -14.407878    -18.866625  \n",
            "25%                0.015873    499.874875           99.207402     49.170263  \n",
            "50%                0.046154    699.465865          128.838980     62.527469  \n",
            "75%                0.097561    800.082161          199.818748     99.967498  \n",
            "max                0.375000   1024.572182          388.551614    233.928316  \n",
            "\n",
            "Correlation with target:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1010: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFeature summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nCorrelation with target:\")\n",
        "df['target'] = (df['target'] == 'bot').astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Sm_Yb2jwFPbl"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        "    'avg_keystroke_time', 'std_keystroke_time',\n",
        "    'avg_pause_time', 'std_pause_time',\n",
        "    'avg_key_hold_time', 'std_key_hold_time',\n",
        "    'typing_speed', 'rhythm_consistency',\n",
        "    'avg_key_distance', 'std_key_distance',\n",
        "    'error_rate', 'correction_rate',\n",
        "    'copy_paste_frequency',\n",
        "    'mouse_speed', 'mouse_acceleration', 'mouse_jerk'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qkfgorbeFqP8"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    problematic_columns = df.columns[df.isin([np.inf, -np.inf, np.nan]).any()].tolist()\n",
        "\n",
        "    print(\"Columns with NaN or infinite values:\")\n",
        "    for col in problematic_columns:\n",
        "        nan_count = df[col].isna().sum()\n",
        "        inf_count = np.isinf(df[col]).sum()\n",
        "        print(f\"{col}: NaN count = {nan_count}, Inf count = {inf_count}\")\n",
        "\n",
        "    for col in problematic_columns:\n",
        "        median_value = df[col].median()\n",
        "        df[col] = df[col].replace([np.inf, -np.inf, np.nan], median_value)\n",
        "\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype in ['float64', 'int64']:\n",
        "            lower_bound = df[column].quantile(0.001)\n",
        "            upper_bound = df[column].quantile(0.999)\n",
        "            df[column] = df[column].clip(lower_bound, upper_bound)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thFoqS0PFvMl",
        "outputId": "441f793d-7031-4aec-c8e6-2850b684cdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns with NaN or infinite values:\n",
            "rhythm_consistency: NaN count = 20, Inf count = 0\n"
          ]
        }
      ],
      "source": [
        "df = clean_data(df)\n",
        "df['target'] = (df['target'] == 'bot').astype(int)\n",
        "\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7Axu-o-JFx7u"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hBUv-AA5F4BB"
      },
      "outputs": [],
      "source": [
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jJxgsENsF8x_"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# Dimension of embeddings\u001b[39;00m\n\u001b[0;32m     48\u001b[0m context_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Number of retrieved documents (contexts)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m rag_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_rag_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_input_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m rag_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     52\u001b[0m rag_model\u001b[38;5;241m.\u001b[39msummary()\n",
            "Cell \u001b[1;32mIn[28], line 29\u001b[0m, in \u001b[0;36mcreate_rag_model\u001b[1;34m(vocab_size, max_input_length, embedding_dim, context_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m context_lstm \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.3\u001b[39m)(context_lstm)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Combine context LSTM output with the query\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_lstm\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Dense layer for generating the output\u001b[39;00m\n\u001b[0;32m     32\u001b[0m dense_out \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(combined)\n",
            "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_rag_model(vocab_size, max_input_length, embedding_dim, context_size):\n",
        "    # Input for the query\n",
        "    query_input = Input(shape=(max_input_length,), name='query_input')\n",
        "\n",
        "    # Input for the context (retrieved documents)\n",
        "    context_input = Input(shape=(context_size, max_input_length), name='context_input')\n",
        "\n",
        "    # Embedding layer for the query\n",
        "    query_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(query_input)\n",
        "\n",
        "    # LSTM for processing the query\n",
        "    query_lstm = LSTM(128, return_sequences=True)(query_embedding)\n",
        "    query_lstm = BatchNormalization()(query_lstm)\n",
        "    query_lstm = Dropout(0.3)(query_lstm)\n",
        "\n",
        "    # Attention mechanism between the query and context\n",
        "    attention_out = Attention()([query_lstm, context_input])\n",
        "\n",
        "    # LSTM for processing the attention output\n",
        "    context_lstm = LSTM(64)(attention_out)\n",
        "    context_lstm = BatchNormalization()(context_lstm)\n",
        "    context_lstm = Dropout(0.3)(context_lstm)\n",
        "\n",
        "    # Combine context LSTM output with the query\n",
        "    combined = tf.concat([context_lstm, query_lstm[:, -1, :]], axis=-1)\n",
        "\n",
        "    # Dense layer for generating the output\n",
        "    dense_out = Dense(32, activation='relu')(combined)\n",
        "    dense_out = BatchNormalization()(dense_out)\n",
        "    dense_out = Dropout(0.3)(dense_out)\n",
        "\n",
        "    # Final output layer\n",
        "    outputs = Dense(1, activation='sigmoid')(dense_out)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[query_input, context_input], outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "vocab_size = 10000  # Example vocabulary size\n",
        "max_input_length = 50  # Maximum length of input queries\n",
        "embedding_dim = 128  # Dimension of embeddings\n",
        "context_size = 10  # Number of retrieved documents (contexts)\n",
        "\n",
        "rag_model = create_rag_model(vocab_size, max_input_length, embedding_dim, context_size)\n",
        "rag_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "rag_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GQtgbgx4GAQZ"
      },
      "outputs": [],
      "source": [
        "model = create_rag_model((1, X_train_reshaped.shape[2]))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qpl4z3UjGjDc"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Xi8MysGm3H",
        "outputId": "5809b8d0-7549-42d5-977b-603af1dda6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 8.8125e-04 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 6.1287e-04 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3896e-04 - val_accuracy: 1.0000 - val_loss: 4.4643e-04 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.4003e-04 - val_accuracy: 1.0000 - val_loss: 3.3491e-04 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8903e-04 - val_accuracy: 1.0000 - val_loss: 2.5310e-04 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.8190e-04 - val_accuracy: 1.0000 - val_loss: 1.9440e-04 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1081e-04 - val_accuracy: 1.0000 - val_loss: 1.5149e-04 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.4799e-04 - val_accuracy: 1.0000 - val_loss: 1.1932e-04 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0948e-04 - val_accuracy: 1.0000 - val_loss: 9.4198e-05 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6642e-04 - val_accuracy: 1.0000 - val_loss: 7.4740e-05 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3640e-04 - val_accuracy: 1.0000 - val_loss: 5.9493e-05 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1491e-04 - val_accuracy: 1.0000 - val_loss: 4.7791e-05 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7389e-05 - val_accuracy: 1.0000 - val_loss: 3.8557e-05 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6591e-05 - val_accuracy: 1.0000 - val_loss: 3.1008e-05 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8017e-05 - val_accuracy: 1.0000 - val_loss: 2.9624e-05 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.4973e-05 - val_accuracy: 1.0000 - val_loss: 2.8188e-05 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.3140e-05 - val_accuracy: 1.0000 - val_loss: 2.6612e-05 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9546e-05 - val_accuracy: 1.0000 - val_loss: 2.4989e-05 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.7800e-05 - val_accuracy: 1.0000 - val_loss: 2.3285e-05 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4891e-05 - val_accuracy: 1.0000 - val_loss: 2.2428e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2423e-05 - val_accuracy: 1.0000 - val_loss: 2.1447e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.9795e-05 - val_accuracy: 1.0000 - val_loss: 2.0426e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8758e-05 - val_accuracy: 1.0000 - val_loss: 1.9347e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5709e-05 - val_accuracy: 1.0000 - val_loss: 1.8210e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3791e-05 - val_accuracy: 1.0000 - val_loss: 1.7017e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2131e-05 - val_accuracy: 1.0000 - val_loss: 1.5804e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.8916e-05 - val_accuracy: 1.0000 - val_loss: 1.4537e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7364e-05 - val_accuracy: 1.0000 - val_loss: 1.3301e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2305e-05 - val_accuracy: 1.0000 - val_loss: 1.2072e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1073e-05 - val_accuracy: 1.0000 - val_loss: 1.0879e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8533e-05 - val_accuracy: 1.0000 - val_loss: 9.7656e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5470e-05 - val_accuracy: 1.0000 - val_loss: 8.6899e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.4095e-05 - val_accuracy: 1.0000 - val_loss: 7.6722e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2151e-05 - val_accuracy: 1.0000 - val_loss: 6.7427e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8144e-05 - val_accuracy: 1.0000 - val_loss: 5.8864e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7390e-05 - val_accuracy: 1.0000 - val_loss: 5.0930e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5704e-05 - val_accuracy: 1.0000 - val_loss: 4.3976e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3846e-05 - val_accuracy: 1.0000 - val_loss: 3.7695e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2420e-05 - val_accuracy: 1.0000 - val_loss: 3.2188e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0824e-05 - val_accuracy: 1.0000 - val_loss: 2.7377e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.0027e-06 - val_accuracy: 1.0000 - val_loss: 2.3250e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.4060e-06 - val_accuracy: 1.0000 - val_loss: 1.9554e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.9684e-06 - val_accuracy: 1.0000 - val_loss: 1.6425e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.0660e-06 - val_accuracy: 1.0000 - val_loss: 1.3730e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0577e-06 - val_accuracy: 1.0000 - val_loss: 1.1558e-06 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4650e-06 - val_accuracy: 1.0000 - val_loss: 9.5960e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0737e-06 - val_accuracy: 1.0000 - val_loss: 7.9973e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.6282e-06 - val_accuracy: 1.0000 - val_loss: 6.6221e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9924e-06 - val_accuracy: 1.0000 - val_loss: 5.5094e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.7278e-06 - val_accuracy: 1.0000 - val_loss: 4.5412e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.3332e-06 - val_accuracy: 1.0000 - val_loss: 3.7607e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8811e-06 - val_accuracy: 1.0000 - val_loss: 3.1332e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.7094e-06 - val_accuracy: 1.0000 - val_loss: 2.5883e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5420e-06 - val_accuracy: 1.0000 - val_loss: 2.1259e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2736e-06 - val_accuracy: 1.0000 - val_loss: 1.7343e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0676e-06 - val_accuracy: 1.0000 - val_loss: 1.4311e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.1689e-07 - val_accuracy: 1.0000 - val_loss: 1.2328e-07 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.6671e-07 - val_accuracy: 1.0000 - val_loss: 9.6963e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.6254e-07 - val_accuracy: 1.0000 - val_loss: 8.0629e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0537e-07 - val_accuracy: 1.0000 - val_loss: 6.6380e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1021e-07 - val_accuracy: 1.0000 - val_loss: 5.4520e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0327e-07 - val_accuracy: 1.0000 - val_loss: 4.5063e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7341e-07 - val_accuracy: 1.0000 - val_loss: 3.7511e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6032e-07 - val_accuracy: 1.0000 - val_loss: 3.9774e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8577e-07 - val_accuracy: 1.0000 - val_loss: 2.5110e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5920e-07 - val_accuracy: 1.0000 - val_loss: 2.0686e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6136e-07 - val_accuracy: 1.0000 - val_loss: 1.7013e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0016e-07 - val_accuracy: 1.0000 - val_loss: 1.4102e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5741e-07 - val_accuracy: 1.0000 - val_loss: 1.1909e-08 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3890e-07 - val_accuracy: 1.0000 - val_loss: 9.9644e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2781e-07 - val_accuracy: 1.0000 - val_loss: 8.7015e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0974e-07 - val_accuracy: 1.0000 - val_loss: 7.0235e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0382e-07 - val_accuracy: 1.0000 - val_loss: 5.9336e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0603e-07 - val_accuracy: 1.0000 - val_loss: 5.1985e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2703e-07 - val_accuracy: 1.0000 - val_loss: 4.1283e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8796e-08 - val_accuracy: 1.0000 - val_loss: 3.4643e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.6007e-08 - val_accuracy: 1.0000 - val_loss: 2.9816e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.6313e-08 - val_accuracy: 1.0000 - val_loss: 2.5688e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.6516e-08 - val_accuracy: 1.0000 - val_loss: 2.2645e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8176e-08 - val_accuracy: 1.0000 - val_loss: 1.8263e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8398e-08 - val_accuracy: 1.0000 - val_loss: 1.5567e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.5158e-08 - val_accuracy: 1.0000 - val_loss: 1.3823e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0460e-08 - val_accuracy: 1.0000 - val_loss: 1.3608e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5062e-08 - val_accuracy: 1.0000 - val_loss: 1.0607e-09 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2495e-08 - val_accuracy: 1.0000 - val_loss: 8.9575e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3392e-08 - val_accuracy: 1.0000 - val_loss: 9.0987e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2267e-08 - val_accuracy: 1.0000 - val_loss: 7.1581e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2003e-08 - val_accuracy: 1.0000 - val_loss: 6.0748e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0556e-08 - val_accuracy: 1.0000 - val_loss: 5.4806e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6507e-08 - val_accuracy: 1.0000 - val_loss: 4.9240e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4577e-08 - val_accuracy: 1.0000 - val_loss: 4.4743e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.9480e-08 - val_accuracy: 1.0000 - val_loss: 3.9193e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3589e-08 - val_accuracy: 1.0000 - val_loss: 3.6183e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8845e-08 - val_accuracy: 1.0000 - val_loss: 3.3386e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2894e-08 - val_accuracy: 1.0000 - val_loss: 3.1228e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0680e-08 - val_accuracy: 1.0000 - val_loss: 2.9195e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1765e-08 - val_accuracy: 1.0000 - val_loss: 2.8177e-10 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0601e-08 - val_accuracy: 1.0000 - val_loss: 2.5999e-10 - learning_rate: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_reshaped, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=64,\n",
        "                    callbacks=[early_stopping, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('rag_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRWxoePLG6wD",
        "outputId": "b3bc1e01-6319-46f2-b9e0-8546b395a54c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5999e-10\n",
            "Test Loss: 2.5999116748387507e-10, Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqE-FuC5HfQM",
        "outputId": "7c81c71f-eebe-4c5f-fb3f-6f7a1d16d2ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
            "Is bot: False, Confidence: 0.9999710321426392\n"
          ]
        }
      ],
      "source": [
        "def predict_bot(new_data):\n",
        "    if new_data.ndim == 1:\n",
        "        new_data = new_data.reshape(1, -1)\n",
        "\n",
        "    new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "    new_data_reshaped = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
        "\n",
        "    prediction = model.predict(new_data_reshaped)\n",
        "\n",
        "    is_bot = prediction > 0.5\n",
        "    confidence = prediction if is_bot else 1 - prediction\n",
        "\n",
        "    return is_bot[0][0], confidence[0][0]\n",
        "\n",
        "real_input = np.array([0.2, 0.05, 0.5, 0.1, 0.1, 0.02, 5.0, 0.8, 2.0, 0.5, 0.01, 0.005, 0.001, 300, 100, 50])\n",
        "is_bot, confidence = predict_bot(real_input)\n",
        "print(f\"Is bot: {is_bot}, Confidence: {confidence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is bot: False, Confidence: 0.31\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming predict_bot function is defined elsewhere\n",
        "def predict_bot(features):\n",
        "    # Replace this function with your actual model prediction logic\n",
        "    # Example mock implementation\n",
        "    is_bot = np.random.choice([True, False])  # Randomly deciding for the example\n",
        "    confidence = np.random.rand()  # Random confidence score for the example\n",
        "    return is_bot, confidence\n",
        "\n",
        "# Function to read features from a CSV file\n",
        "def read_features_from_csv(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Assuming the CSV has a single row with the features in order\n",
        "    features = df.iloc[0].values  # Get the first row as a numpy array\n",
        "\n",
        "    return features\n",
        "\n",
        "# Input CSV file path\n",
        "csv_file_path = (r'C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\INTEL CBE\\features.csv' ) # Update this to your actual file path\n",
        "\n",
        "# Read features from CSV\n",
        "real_input = read_features_from_csv(csv_file_path)\n",
        "\n",
        "# Ensure the features are in the correct format\n",
        "real_input = np.array(real_input)\n",
        "\n",
        "# Predict if it's a bot and get confidence\n",
        "is_bot, confidence = predict_bot(real_input)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Is bot: {is_bot}, Confidence: {confidence:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
