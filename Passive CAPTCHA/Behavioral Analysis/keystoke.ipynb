{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import load\n",
    "from joblib import dump\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_csv(r'C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\sih24\\ml keystroke\\keystroke ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0        s002             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1        s002             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2        s002             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3        s002             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4        s002             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "...       ...           ...  ...       ...          ...          ...     ...   \n",
       "20395    s057             8   46    0.0884       0.0685      -0.0199  0.1095   \n",
       "20396    s057             8   47    0.0655       0.0630      -0.0025  0.0910   \n",
       "20397    s057             8   48    0.0939       0.1189       0.0250  0.1008   \n",
       "20398    s057             8   49    0.0923       0.1294       0.0371  0.0913   \n",
       "20399    s057             8   50    0.0596       0.1310       0.0714  0.0992   \n",
       "\n",
       "       DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0      0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1      0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2      0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3      0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4      0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "20395  0.1290  0.0195  0.0945  ...  0.1219  0.1383  0.0164  0.0820  0.1329   \n",
       "20396  0.1148  0.0238  0.0916  ...  0.1008  0.0512 -0.0496  0.1037  0.0868   \n",
       "20397  0.1122  0.0114  0.0721  ...  0.0913  0.1169  0.0256  0.0689  0.1311   \n",
       "20398  0.0990  0.0077  0.0992  ...  0.0882  0.0821 -0.0061  0.0576  0.0697   \n",
       "20399  0.1103  0.0111  0.0998  ...  0.0969  0.0784 -0.0185  0.0790  0.1133   \n",
       "\n",
       "       UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0      0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1      0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2      0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3      0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4      0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "...       ...     ...          ...          ...       ...  \n",
       "20395  0.0509  0.1005       0.2054       0.1049    0.1047  \n",
       "20396 -0.0169  0.1445       0.2206       0.0761    0.1198  \n",
       "20397  0.0622  0.1034       0.2017       0.0983    0.0905  \n",
       "20398  0.0121  0.0979       0.1917       0.0938    0.0931  \n",
       "20399  0.0343  0.0807       0.1993       0.1186    0.1018  \n",
       "\n",
       "[20400 rows x 34 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop1=['subject','sessionIndex','rep']\n",
    "df=human_df.drop(columns=drop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['H.period', 'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i',\n",
       "       'H.i', 'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five', 'UD.e.five', 'H.five',\n",
       "       'DD.five.Shift.r', 'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o',\n",
       "       'UD.Shift.r.o', 'H.o', 'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n',\n",
       "       'H.n', 'DD.n.l', 'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return',\n",
       "       'H.Return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['H.period', 'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i',\n",
    "       'H.i', 'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five', 'UD.e.five', 'H.five',\n",
    "       'DD.five.Shift.r', 'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o',\n",
    "       'UD.Shift.r.o', 'H.o', 'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n',\n",
    "       'H.n', 'DD.n.l', 'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return',\n",
    "       'H.Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df[features], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(X, Y):\n",
    "    return np.sum(np.abs(X - Y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(X_train, X_test, threshold_percentile=85):\n",
    "    anomalies = []\n",
    "    \n",
    "    for x_test in X_test:\n",
    "        distances = manhattan_distance(X_train, x_test)  # Compute distances to all training points\n",
    "        min_distance = np.min(distances)  # Minimum distance to any training point\n",
    "        \n",
    "        # Compute threshold based on the training set distances\n",
    "        threshold = np.percentile(distances, threshold_percentile)\n",
    "        \n",
    "        # If the minimum distance is greater than the threshold, it's an anomaly\n",
    "        if min_distance > threshold:\n",
    "            anomalies.append(True)  # Anomaly (likely bot)\n",
    "        else:\n",
    "            anomalies.append(False)  # Not an anomaly (likely human)\n",
    "    \n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = detect_anomalies(X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['anomaly'] = anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i     H.i  \\\n",
      "3482     0.1452       0.1982       0.0530  0.1309  0.1082 -0.0227  0.1454   \n",
      "9387     0.0905       0.1485       0.0580  0.0708  0.1273  0.0565  0.0541   \n",
      "4269     0.0673       0.1192       0.0519  0.0692  0.0597 -0.0095  0.0628   \n",
      "20135    0.0762       0.3185       0.2423  0.0936  0.0976  0.0040  0.0868   \n",
      "18788    0.1060       0.1400       0.0340  0.0617  0.1097  0.0480  0.1087   \n",
      "...         ...          ...          ...     ...     ...     ...     ...   \n",
      "14200    0.2189       1.4485       1.2296  0.1150  0.2276  0.1126  0.1198   \n",
      "20066    0.1424       0.3298       0.1874  0.0810  0.0963  0.0153  0.0913   \n",
      "6612     0.0987       0.2176       0.1189  0.0995  0.1922  0.0927  0.1101   \n",
      "16974    0.0836       0.4024       0.3188  0.1219  0.1694  0.0475  0.0551   \n",
      "4356     0.0919       0.1124       0.0205  0.1095  0.1209  0.0114  0.0781   \n",
      "\n",
      "       DD.i.e  UD.i.e     H.e  ...  DD.a.n  UD.a.n     H.n  DD.n.l  UD.n.l  \\\n",
      "3482   0.1367 -0.0087  0.1206  ...  0.1106 -0.0683  0.1481  0.1156 -0.0325   \n",
      "9387   0.0594  0.0053  0.0911  ...  0.1123  0.0265  0.1014  0.0868 -0.0146   \n",
      "4269   0.0607 -0.0021  0.0713  ...  0.0982  0.0106  0.0879  0.1066  0.0187   \n",
      "20135  0.1216  0.0348  0.0702  ...  0.2981  0.2371  0.0799  0.2110  0.1311   \n",
      "18788  0.0936 -0.0151  0.0478  ...  0.1121 -0.0258  0.1015  0.0759 -0.0256   \n",
      "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
      "14200  0.1573  0.0375  0.0989  ...  0.1451 -0.0193  0.1159  0.2319  0.1160   \n",
      "20066  0.1064  0.0151  0.0697  ...  0.0916 -0.0040  0.0465  0.2248  0.1783   \n",
      "6612   0.1587  0.0486  0.0787  ...  0.1297  0.0885  0.0702  0.1520  0.0818   \n",
      "16974  0.1535  0.0984  0.1274  ...  0.2280  0.0763  0.0718  0.3083  0.2365   \n",
      "4356   0.0853  0.0072  0.1029  ...  0.0745 -0.0111  0.0558  0.0769  0.0211   \n",
      "\n",
      "          H.l  DD.l.Return  UD.l.Return  H.Return  anomaly  \n",
      "3482   0.1639       0.2744       0.1105    0.1399    False  \n",
      "9387   0.0948       0.2398       0.1450    0.0774    False  \n",
      "4269   0.0898       0.1876       0.0978    0.0721    False  \n",
      "20135  0.0712       0.3295       0.2583    0.0987    False  \n",
      "18788  0.0863       0.1909       0.1046    0.0623    False  \n",
      "...       ...          ...          ...       ...      ...  \n",
      "14200  0.0894       0.2404       0.1510    0.1050    False  \n",
      "20066  0.0918       0.2056       0.1138    0.1295    False  \n",
      "6612   0.0750       0.2472       0.1722    0.0966    False  \n",
      "16974  0.0776       0.6418       0.5642    0.0697    False  \n",
      "4356   0.0995       0.2068       0.1073    0.0803    False  \n",
      "\n",
      "[4080 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bot_data(num_samples, feature_size):\n",
    "    # Create uniform bot-like behavior with small variation in timings\n",
    "    bot_data = np.full((num_samples, feature_size), 0.3) + np.random.normal(0, 0.2, (num_samples, feature_size))\n",
    "    return bot_data\n",
    "\n",
    "# Number of samples and feature size (same as human data)\n",
    "num_bot_samples = 50\n",
    "feature_size = X_train_scaled.shape[1]  # Based on the number of features in the training set\n",
    "\n",
    "# Generate bot test data\n",
    "bot_test_data = generate_bot_data(num_bot_samples, feature_size)\n",
    "\n",
    "# Combine human and bot test data\n",
    "X_test_combined = np.vstack([X_test_scaled, bot_test_data])\n",
    "\n",
    "# Create labels for evaluation (human = 0, bot = 1)\n",
    "y_test = np.hstack([np.zeros(len(X_test_scaled)), np.ones(num_bot_samples)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted anomalies (1 = bot, 0 = human): [0 0 0 ... 0 0 0]\n",
      "Actual labels (1 = bot, 0 = human): [0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the combined test set (human + bot data)\n",
    "anomalies = detect_anomalies(X_train_scaled, X_test_combined)\n",
    "\n",
    "# Compare detected anomalies with actual labels (0 for human, 1 for bot)\n",
    "y_pred = np.array(anomalies).astype(int)\n",
    "\n",
    "# Display results\n",
    "print(\"Predicted anomalies (1 = bot, 0 = human):\", y_pred)\n",
    "print(\"Actual labels (1 = bot, 0 = human):\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Human       0.99      1.00      0.99      4080\n",
      "         Bot       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.99      4130\n",
      "   macro avg       0.49      0.50      0.50      4130\n",
      "weighted avg       0.98      0.99      0.98      4130\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4080    0]\n",
      " [  50    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['Human', 'Bot']))\n",
    "\n",
    "# Print confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test_combined)\n",
    "\n",
    "# Plot the human and bot points\n",
    "plt.scatter(X_test_pca[:len(X_test_scaled), 0], X_test_pca[:len(X_test_scaled), 1], color='blue', label='Human')\n",
    "plt.scatter(X_test_pca[len(X_test_scaled):, 0], X_test_pca[len(X_test_scaled):, 1], color='red', label='Bot')\n",
    "plt.legend()\n",
    "plt.title(\"PCA Visualization of Human vs Bot Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"keystroke ds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = data[\"subject\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateEER(user_scores, imposter_scores):\n",
    "    labels = [0]*len(user_scores) + [1]*len(imposter_scores)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, user_scores + imposter_scores)\n",
    "    missrates = 1 - tpr\n",
    "    farates = fpr\n",
    "    dists = missrates - farates\n",
    "    idx1 = np.argmin(dists[dists >= 0])\n",
    "    idx2 = np.argmax(dists[dists < 0])\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDetector:\n",
    "    \n",
    "    def __init__(self, subjects):\n",
    "        self.train = train\n",
    "        self.test_genuine = test_genuine\n",
    "        self.test_imposter = test_imposter\n",
    "        self.user_scores = []\n",
    "        self.imposter_scores = []\n",
    "        self.mean_vector = []\n",
    "        self.subjects = subjects\n",
    "        \n",
    "    def training(self):\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        \n",
    "    def testing(self):\n",
    "        for i in range(self.test_genuine.shape[0]):\n",
    "            cur_score = np.linalg.norm(self.test_genuine.iloc[i].values - self.mean_vector)\n",
    "            self.user_scores.append(cur_score)\n",
    "            \n",
    "        for i in range(self.test_imposter.shape[0]):\n",
    "            cur_score = np.linalg.norm(self.test_imposter.iloc[i].values - self.mean_vector)\n",
    "            self.imposter_scores.append(cur_score)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        eers = []\n",
    "        \n",
    "        for subject in subjects:\n",
    "            \n",
    "            self.user_scores = []\n",
    "            self.imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            self.train = genuine_user_data[:200]\n",
    "    \n",
    "            # True set (200 records)\n",
    "            self.test_genuine = genuine_user_data[200:]\n",
    "    \n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            self.test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            \n",
    "            self.training()\n",
    "            \n",
    "            self.testing()\n",
    "    \n",
    "            eers.append(evaluateEER(self.user_scores, self.imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanNormedDetector:\n",
    "    \n",
    "    def __init__(self, subjects):\n",
    "        self.train = train\n",
    "        self.test_genuine = test_genuine\n",
    "        self.test_imposter = test_imposter\n",
    "        self.user_scores = []\n",
    "        self.imposter_scores = []\n",
    "        self.mean_vector = []\n",
    "        self.subjects = subjects\n",
    "        \n",
    "    def training(self):\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        \n",
    "    def testing(self):\n",
    "        for i in range(self.test_genuine.shape[0]):\n",
    "            cur_score = np.linalg.norm(self.test_genuine.iloc[i].values - self.mean_vector)**2\n",
    "            cur_score = cur_score / np.linalg.norm(self.test_genuine.iloc[i].values)\n",
    "            cur_score = cur_score / np.linalg.norm(self.mean_vector)\n",
    "            self.user_scores.append(cur_score)\n",
    "            \n",
    "        for i in range(self.test_imposter.shape[0]):\n",
    "            cur_score = np.linalg.norm(self.test_imposter.iloc[i].values - self.mean_vector)**2\n",
    "            cur_score = cur_score / np.linalg.norm(self.test_imposter.iloc[i].values)\n",
    "            cur_score = cur_score / np.linalg.norm(self.mean_vector)\n",
    "            self.imposter_scores.append(cur_score)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        eers = []\n",
    "        \n",
    "        for subject in subjects:\n",
    "            \n",
    "            self.user_scores = []\n",
    "            self.imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            self.train = genuine_user_data[:200]\n",
    "    \n",
    "            # True set (200 records)\n",
    "            self.test_genuine = genuine_user_data[200:]\n",
    "    \n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            self.test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            \n",
    "            self.training()\n",
    "            \n",
    "            self.testing()\n",
    "    \n",
    "            eers.append(evaluateEER(self.user_scores, self.imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManhattanDetector:\n",
    "    \n",
    "    def __init__(self, subjects):\n",
    "        self.train = train\n",
    "        self.test_genuine = test_genuine\n",
    "        self.test_imposter = test_imposter\n",
    "        self.user_scores = []\n",
    "        self.imposter_scores = []\n",
    "        self.mean_vector = []\n",
    "        self.subjects = subjects\n",
    "        \n",
    "    def training(self):\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        \n",
    "    def testing(self):\n",
    "        for i in range(self.test_genuine.shape[0]):\n",
    "            cur_score = cityblock(self.test_genuine.iloc[i].values, self.mean_vector)\n",
    "            self.user_scores.append(cur_score)\n",
    "            \n",
    "        for i in range(self.test_imposter.shape[0]):\n",
    "            cur_score = cityblock(self.test_imposter.iloc[i].values, self.mean_vector)\n",
    "            self.imposter_scores.append(cur_score)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        eers = []\n",
    "        \n",
    "        for subject in subjects:\n",
    "            \n",
    "            self.user_scores = []\n",
    "            self.imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            self.train = genuine_user_data[:200]\n",
    "    \n",
    "            # True set (200 records)\n",
    "            self.test_genuine = genuine_user_data[200:]\n",
    "    \n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            self.test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            \n",
    "            self.training()\n",
    "            \n",
    "            self.testing()\n",
    "    \n",
    "            eers.append(evaluateEER(self.user_scores, self.imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManhattanFilteredDetector:\n",
    "    \n",
    "    def __init__(self, subjects):\n",
    "        self.train = train\n",
    "        self.test_genuine = test_genuine\n",
    "        self.test_imposter = test_imposter\n",
    "        self.user_scores = []\n",
    "        self.imposter_scores = []\n",
    "        self.mean_vector = []\n",
    "        self.subjects = subjects\n",
    "        \n",
    "    def training(self):\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        self.std_vector = self.train.std().values\n",
    "        dropping_indices = []\n",
    "        for i in range(train.shape[0]):\n",
    "            cur_score = euclidean(self.train.iloc[i].values, self.mean_vector)\n",
    "            if (cur_score > 3*self.std_vector).all() == True:\n",
    "                dropping_indices.append(i)\n",
    "        self.train = self.train.drop(self.train.index[dropping_indices])\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        \n",
    "    def testing(self):\n",
    "        for i in range(self.test_genuine.shape[0]):\n",
    "            cur_score = cityblock(self.test_genuine.iloc[i].values, self.mean_vector)\n",
    "            self.user_scores.append(cur_score)\n",
    "            \n",
    "        for i in range(self.test_imposter.shape[0]):\n",
    "            cur_score = cityblock(self.test_imposter.iloc[i].values, self.mean_vector)\n",
    "            self.imposter_scores.append(cur_score)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        eers = []\n",
    "        \n",
    "        for subject in subjects:\n",
    "            \n",
    "            self.user_scores = []\n",
    "            self.imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            self.train = genuine_user_data[:200]\n",
    "    \n",
    "            # True set (200 records)\n",
    "            self.test_genuine = genuine_user_data[200:]\n",
    "    \n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            self.test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            \n",
    "            self.training()\n",
    "            \n",
    "            self.testing()\n",
    "    \n",
    "            eers.append(evaluateEER(self.user_scores, self.imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cityblock, mahalanobis, euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mManhattanFilteredDetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mManhattanFilteredDetector.__init__\u001b[1;34m(self, subjects)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, subjects):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_genuine \u001b[38;5;241m=\u001b[39m test_genuine\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_imposter \u001b[38;5;241m=\u001b[39m test_imposter\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "ManhattanFilteredDetector(subjects).evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(eers), np\u001b[38;5;241m.\u001b[39mstd(eers)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Run evaluation for ManhattanFilteredDetector\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m mean_eer, std_eer \u001b[38;5;241m=\u001b[39m \u001b[43mManhattanFilteredDetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean EER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_eer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std EER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_eer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 84\u001b[0m, in \u001b[0;36mManhattanFilteredDetector.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting()\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Calculate EER for this subject\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     eers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluateEER\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimposter_scores\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(eers), np\u001b[38;5;241m.\u001b[39mstd(eers)\n",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m, in \u001b[0;36mevaluateEER\u001b[1;34m(user_scores, imposter_scores)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluateEER\u001b[39m(user_scores, imposter_scores):\n\u001b[0;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(user_scores) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(imposter_scores)\n\u001b[1;32m----> 5\u001b[0m     fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimposter_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     missrates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tpr\n\u001b[0;32m      7\u001b[0m     farates \u001b[38;5;241m=\u001b[39m fpr\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1095\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    994\u001b[0m     {\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m ):\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1095\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:810\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    808\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[0;32m    809\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m--> 810\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:200\u001b[0m, in \u001b[0;36massert_all_finite\u001b[1;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[0;32m    175\u001b[0m     X,\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    180\u001b[0m ):\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Padmajaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "subjects = data[\"subject\"].unique()\n",
    "\n",
    "def evaluateEER(user_scores, imposter_scores):\n",
    "    labels = [0]*len(user_scores) + [1]*len(imposter_scores)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, user_scores + imposter_scores)\n",
    "    missrates = 1 - tpr\n",
    "    farates = fpr\n",
    "    dists = missrates - farates\n",
    "    idx1 = np.argmin(dists[dists >= 0])\n",
    "    idx2 = np.argmax(dists[dists < 0])\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "    a = (x[0] - x[1]) / (y[1] - x[1] - y[0] + x[0])\n",
    "    eer = x[0] + a * (y[0] - x[0])\n",
    "    return eer\n",
    "\n",
    "class ManhattanFilteredDetector:\n",
    "    \n",
    "    def __init__(self, subjects):\n",
    "        self.user_scores = []\n",
    "        self.imposter_scores = []\n",
    "        self.mean_vector = []\n",
    "        self.std_vector = []\n",
    "        self.subjects = subjects\n",
    "        \n",
    "    def training(self):\n",
    "        # Compute mean and std dev vectors for the training data\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        self.std_vector = self.train.std().values\n",
    "        \n",
    "        dropping_indices = []\n",
    "        \n",
    "        # Check each training sample\n",
    "        for i in range(self.train.shape[0]):\n",
    "            cur_score = euclidean(self.train.iloc[i].values, self.mean_vector)\n",
    "            \n",
    "            # Drop if any feature exceeds 3 times its std dev from the mean\n",
    "            if (cur_score > 3 * self.std_vector).any():\n",
    "                dropping_indices.append(i)\n",
    "        \n",
    "        # Drop the outliers from the training set\n",
    "        self.train = self.train.drop(self.train.index[dropping_indices])\n",
    "        \n",
    "        # Recompute mean after removing outliers\n",
    "        self.mean_vector = self.train.mean().values\n",
    "        \n",
    "    def testing(self):\n",
    "        # Compute scores for genuine test set (same user)\n",
    "        for i in range(self.test_genuine.shape[0]):\n",
    "            cur_score = cityblock(self.test_genuine.iloc[i].values, self.mean_vector)\n",
    "            self.user_scores.append(cur_score)\n",
    "        \n",
    "        # Compute scores for imposters\n",
    "        for i in range(self.test_imposter.shape[0]):\n",
    "            cur_score = cityblock(self.test_imposter.iloc[i].values, self.mean_vector)\n",
    "            self.imposter_scores.append(cur_score)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        eers = []\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            \n",
    "            self.user_scores = []\n",
    "            self.imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            self.train = genuine_user_data[:200]\n",
    "    \n",
    "            # True set (200 records)\n",
    "            self.test_genuine = genuine_user_data[200:]\n",
    "    \n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            self.test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            \n",
    "            # Train and test for each subject\n",
    "            self.training()\n",
    "            self.testing()\n",
    "    \n",
    "            # Calculate EER for this subject\n",
    "            eers.append(evaluateEER(self.user_scores, self.imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)\n",
    "\n",
    "# Run evaluation for ManhattanFilteredDetector\n",
    "mean_eer, std_eer = ManhattanFilteredDetector(subjects).evaluate()\n",
    "print(f\"Mean EER: {mean_eer:.4f}, Std EER: {std_eer:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
